## Parameter Efficient Finetuning
- [LoRA](https://arxiv.org/abs/2106.09685) - Original PEFT method
- [QLoRA](http://arxiv.org/abs/2305.14314) - Quantized version of LoRA
- [FSDP+QLoRA](https://www.answer.ai/posts/2024-03-06-fsdp-qlora.html) - Distributed training guide

## Preference Learning
- [DPO](https://arxiv.org/abs/2305.18290) - Direct Preference Optimization
- [PPO](https://arxiv.org/abs/1707.06347) - Proximal Policy Optimization
- [OpenAI Preference Finetuning](https://platform.openai.com/docs/guides/fine-tuning#preference) - Official implementation

## Feature Engineering
- [ReFT](https://arxiv.org/abs/2404.03592) - Feature-based finetuning

## Synthetic Data
- [Orca 3/AgentInstruct](https://www.microsoft.com/en-us/research/blog/orca-agentinstruct-agentic-flows-can-be-effective-synthetic-data-generators/) - Agent-based data generation
- [NeurIPS Synthetic Data](https://www.latent.space/p/2024-syndata-smolmodels) - Latest research overview

## RL & Reasoning
- [OpenAI RL Finetuning](https://www.interconnects.ai/p/openais-reinforcement-finetuning) - Claude analysis
- [Let's Verify Step By Step](https://arxiv.org/abs/2305.20050) - Verification framework
- [Noam Brown Talks](https://x.com/swyx/status/1867990396762243324) - Implementation insights